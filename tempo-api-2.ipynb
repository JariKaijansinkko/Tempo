{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://jira.eficode.com\"\n",
    "access_token = os.getenv('JIRA_API_TOKEN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url = f'{base_url}/rest/tempo-planning/1/allocation'\n",
    "header = {'Authorization': f'Bearer {access_token}', 'Content-Type': 'application/json'}\n",
    "res = requests.get(url=url, headers=header)\n",
    "\n",
    "print(res.status_code)\n",
    "data = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plan_id</th>\n",
       "      <th>employee</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>hours_day</th>\n",
       "      <th>employee_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>607</td>\n",
       "      <td>rasmus.paltschik</td>\n",
       "      <td>2023-04-19</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>541</td>\n",
       "      <td>juha.patrikainen</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>4.615278</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>599</td>\n",
       "      <td>rasmus.paltschik</td>\n",
       "      <td>2023-04-20</td>\n",
       "      <td>2023-04-20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>533</td>\n",
       "      <td>jukka.haavisto</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>586</td>\n",
       "      <td>arto.kovalainen</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>553</td>\n",
       "      <td>tuomas.kara</td>\n",
       "      <td>2023-04-19</td>\n",
       "      <td>2023-04-20</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>549</td>\n",
       "      <td>tapio.tuomisto</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>578</td>\n",
       "      <td>ilkka.vaisanen</td>\n",
       "      <td>2023-04-17</td>\n",
       "      <td>2023-06-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>545</td>\n",
       "      <td>Antti-juho.nieminen</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    plan_id             employee      start        end  hours_day  \\\n",
       "0       607     rasmus.paltschik 2023-04-19 2023-05-31   4.500000   \n",
       "1       541     juha.patrikainen 2023-01-01 2023-06-30   6.000000   \n",
       "2       376                    1 2023-01-01 2023-12-31   4.615278   \n",
       "3       599     rasmus.paltschik 2023-04-20 2023-04-20   1.000000   \n",
       "4       533       jukka.haavisto 2023-04-01 2023-06-30   0.750000   \n",
       "..      ...                  ...        ...        ...        ...   \n",
       "67      586      arto.kovalainen 2023-05-08 2023-05-10   1.000000   \n",
       "68      553          tuomas.kara 2023-04-19 2023-04-20   2.400000   \n",
       "69      549       tapio.tuomisto 2023-03-01 2023-04-30   0.500000   \n",
       "70      578       ilkka.vaisanen 2023-04-17 2023-06-02   1.000000   \n",
       "71      545  Antti-juho.nieminen 2023-04-04 2023-05-05   3.000000   \n",
       "\n",
       "    employee_day  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "..           ...  \n",
       "67           NaN  \n",
       "68           NaN  \n",
       "69           NaN  \n",
       "70           NaN  \n",
       "71           NaN  \n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['plan_id', 'employee', 'start', 'end', 'hours_day', 'employee_day'])\n",
    "\n",
    "for plan in data:\n",
    "    row = {'plan_id': plan['id'], 'employee': plan['assignee']['key'], 'start': plan['start'], 'end': plan['end'], 'hours_day': int(plan['secondsPerDay'])/(60*60)}\n",
    "    df.loc[len(df)] = row\n",
    "\n",
    "df['start'] = pd.to_datetime(df['start'], format='%Y/%m/%d')\n",
    "df['end'] = pd.to_datetime(df['end'], format='%Y/%m/%d')\n",
    "\n",
    "dfgroup = df\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n\\n# Create a new data frame with every day of the project\\ndate_range = pd.date_range(start=employee_data['start'].min(), end=employee_data['end'].max(), freq='D')\\nproject_dates = pd.DataFrame({'Project Dates': date_range})\\n\\n# Merge the new data frame with the employee data\\nmerged_data = pd.merge(project_dates, employee_data, how='left', left_on='Project Dates', right_on='start')\\n\\n# Fill in missing employees\\nmerged_data['employee'].fillna(method='ffill', inplace=True)\\n\\n# Create a new column with plan_id, employee and date for each day of the project for each employee\\nplanned_id = merged_data['plan_id'].apply(str)\\nmerged_data['Employee Project Dates'] = planned_id + ': ' + merged_data['employee'] + ': ' + merged_data['Project Dates'].dt.strftime('%Y-%m-%d')\\n\\n# Pivot the data to create a new column for each employee\\npivot_data = merged_data.pivot(index='Employee Project Dates', columns='employee', values='hours_day')\\n\\n# Reset the index and rename the columns\\npivot_data = pivot_data.reset_index().rename_axis(None, axis=1)\\n\\n# Display the updated data frame\\n# print(pivot_data)\\n\\n# Write the updated data frame to a new CSV file\\nmerged_data.to_csv('updated_employee_data.csv', index=False)\\n \""
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "employee_data = df.copy()\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "# Create a new data frame with every day of the project\n",
    "date_range = pd.date_range(start=employee_data['start'].min(), end=employee_data['end'].max(), freq='D')\n",
    "project_dates = pd.DataFrame({'Project Dates': date_range})\n",
    "\n",
    "# Merge the new data frame with the employee data\n",
    "merged_data = pd.merge(project_dates, employee_data, how='left', left_on='Project Dates', right_on='start')\n",
    "\n",
    "# Fill in missing employees\n",
    "merged_data['employee'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Create a new column with plan_id, employee and date for each day of the project for each employee\n",
    "planned_id = merged_data['plan_id'].apply(str)\n",
    "merged_data['Employee Project Dates'] = planned_id + ': ' + merged_data['employee'] + ': ' + merged_data['Project Dates'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Pivot the data to create a new column for each employee\n",
    "pivot_data = merged_data.pivot(index='Employee Project Dates', columns='employee', values='hours_day')\n",
    "\n",
    "# Reset the index and rename the columns\n",
    "pivot_data = pivot_data.reset_index().rename_axis(None, axis=1)\n",
    "\n",
    "# Display the updated data frame\n",
    "# print(pivot_data)\n",
    "\n",
    "# Write the updated data frame to a new CSV file\n",
    "merged_data.to_csv('updated_employee_data.csv', index=False)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date_range'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\JariKaijansinkko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\JariKaijansinkko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\JariKaijansinkko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date_range'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[180], line 77\u001b[0m\n\u001b[0;32m     74\u001b[0m dates_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m: date_range})\n\u001b[0;32m     76\u001b[0m \u001b[39m# Merge the date dataframe with the employee allocations for this employee\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m employee_allocations_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(row[\u001b[39m'\u001b[39;49m\u001b[39mdate_range\u001b[39;49m\u001b[39m'\u001b[39;49m], columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mAllocation\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     78\u001b[0m dates_with_allocations_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(dates_df, employee_allocations_df, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m, left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m, right_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     80\u001b[0m \u001b[39m# Fill any missing allocations with 0\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JariKaijansinkko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JariKaijansinkko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\JariKaijansinkko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date_range'"
     ]
    }
   ],
   "source": [
    "\"\"\" def sum_values(row):\n",
    "    dates = pd.date_range(row['start'],row['end'],freq='D')\n",
    "    return pd.Series({'dates':dates, 'hours':row['hours_day']})\n",
    "\n",
    "\n",
    "employee_data  \"\"\"\n",
    "\n",
    "\"\"\" \n",
    "def generate_date_range(row):\n",
    "    return pd.date_range(start=row['start'], end=row['end'], freq='D')\n",
    "# apply the function to each row, resulting in a new column with the date range as a pandas.date_range object\n",
    "df['date_range'] = df.apply(generate_date_range, axis=1) \"\"\"\n",
    "\n",
    "df['date_range'] = df.apply(lambda row: pd.date_range(start=row['start'], end=row['end'], freq='D'), axis=1)\n",
    "\n",
    "df_exploded = df.explode('date_range')\n",
    "\n",
    "df_summed = df_exploded.groupby(['date_range', 'employee'])['hours_day'].sum().reset_index()\n",
    "# df_summed\n",
    "plans = df_exploded.groupby(['date_range', 'employee'])['plan_id'].agg(lambda x: list(x)).reset_index()\n",
    "# Merge the new data frame with the employee data\n",
    "merged_data = pd.merge(df_summed, plans, how='left')\n",
    "# Read in the date table\n",
    "date_table = pd.read_csv('Datetable.csv', parse_dates=['Date'])\n",
    "# Convert the date column to a datetime object\n",
    "date_table['Date'] = pd.to_datetime(date_table['Date'])\n",
    "\n",
    "date_table.set_index('Date', inplace=True)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the date table and employee data table\n",
    "date_df = pd.read_csv('Datetable.csv')\n",
    "\n",
    "\n",
    "# Create a new dataframe to hold the merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each employee in the employee data table\n",
    "for index, row in employee_data.iterrows():\n",
    "    # Create a new dataframe to hold the merged data for this employee\n",
    "    employee_merged_df = pd.DataFrame()\n",
    "    \n",
    "    # Get the date range for this employee\n",
    "    date_range = pd.date_range(start=row['start'], end=row['end'])\n",
    "    \n",
    "    # Create a new dataframe with the date range\n",
    "    dates_df = pd.DataFrame({'Date': date_range})\n",
    "    \n",
    "    # Merge the date dataframe with the employee allocations for this employee\n",
    "    employee_allocations_df = pd.DataFrame(row['date_range'], columns=['Allocation'])\n",
    "    dates_with_allocations_df = pd.merge(dates_df, employee_allocations_df, how='left', left_on='Date', right_index=True)\n",
    "    \n",
    "    # Fill any missing allocations with 0\n",
    "    dates_with_allocations_df.fillna(0, inplace=True)\n",
    "    \n",
    "    # Add the employee name to the dataframe\n",
    "    dates_with_allocations_df['Employee'] = row['Employee Name']\n",
    "    \n",
    "    # Append the merged data for this employee to the overall merged dataframe\n",
    "    merged_df = pd.concat([merged_df, dates_with_allocations_df])\n",
    "\n",
    "\n",
    "\n",
    "# Write the merged data to a new CSV file\n",
    "# merged_df.to_csv('merged_data.csv', index=False)\n",
    "\n",
    "\n",
    "merged_data['allocation'] = 'Partly allocated'\n",
    "\n",
    "merged_data.loc[merged_data['hours_day'] >= 7.5, 'allocation'] = 'Fully allocated'\n",
    "merged_data.loc[merged_data['hours_day'] <= 0.1, 'allocation'] = 'Not allocated'\n",
    "\n",
    "merged_data['coefficient'] = 0.5\n",
    "\n",
    "merged_data.loc[merged_data['hours_day'] >= 7.5, 'coefficient'] = 1.0\n",
    "merged_data.loc[merged_data['hours_day'] <= 0.1, 'coefficient'] = 0.0\n",
    "# merged_data.loc[merged_data['hours_day'] < 7.5 and merged_data['hours_day'] > 0.1 , 'allocation'] = 'Partly allocated'\n",
    "# merged_data['allocation'] = ''\n",
    "\n",
    "\n",
    "\n",
    "# rowvalue\n",
    "# plans\n",
    "# df_summed\n",
    "# merged_data\n",
    "\n",
    "# Write the updated data frame to a new CSV file\n",
    "merged_data.to_csv('updated_employee_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data.groupby('employee').sum()\n",
    "\n",
    "# pivot_data\n",
    "\n",
    "# date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(f'{base_url}/rest/tempo-teams/2/team', headers=header)\n",
    "teams = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jani.lundan\n",
      "jarkko.sillanpaa\n",
      "juha.patrikainen\n",
      "juho.lehtonen\n",
      "jukka.haavisto\n",
      "jyri.tienhaara\n",
      "kai.jokiniemi\n",
      "matias.ijas\n",
      "mika.tavi\n",
      "tapio.tuomisto\n",
      "teemu.partanen\n",
      "tuomas.kara\n",
      "vilma.pohjonen\n"
     ]
    }
   ],
   "source": [
    "team_members = requests.get(f'{base_url}/rest/tempo-teams/2/team/42/member', headers=header).json()\n",
    "for member in team_members:\n",
    "    print(member['member']['name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
