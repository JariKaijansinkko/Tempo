{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://jira.eficode.com\"\n",
    "access_token = os.getenv('JIRA_API_TOKEN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url = f'{base_url}/rest/tempo-planning/1/allocation'\n",
    "header = {'Authorization': f'Bearer {access_token}', 'Content-Type': 'application/json'}\n",
    "res = requests.get(url=url, headers=header)\n",
    "\n",
    "print(res.status_code)\n",
    "data = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plan_id</th>\n",
       "      <th>employee</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>hours_day</th>\n",
       "      <th>employee_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>607</td>\n",
       "      <td>rasmus.paltschik</td>\n",
       "      <td>2023-04-19</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>541</td>\n",
       "      <td>juha.patrikainen</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>4.615278</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>599</td>\n",
       "      <td>rasmus.paltschik</td>\n",
       "      <td>2023-04-20</td>\n",
       "      <td>2023-04-20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>533</td>\n",
       "      <td>jukka.haavisto</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>586</td>\n",
       "      <td>arto.kovalainen</td>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>553</td>\n",
       "      <td>tuomas.kara</td>\n",
       "      <td>2023-04-19</td>\n",
       "      <td>2023-04-20</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>549</td>\n",
       "      <td>tapio.tuomisto</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>578</td>\n",
       "      <td>ilkka.vaisanen</td>\n",
       "      <td>2023-04-17</td>\n",
       "      <td>2023-06-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>545</td>\n",
       "      <td>Antti-juho.nieminen</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    plan_id             employee      start        end  hours_day  \\\n",
       "0       607     rasmus.paltschik 2023-04-19 2023-05-31   4.500000   \n",
       "1       541     juha.patrikainen 2023-01-01 2023-06-30   6.000000   \n",
       "2       376                    1 2023-01-01 2023-12-31   4.615278   \n",
       "3       599     rasmus.paltschik 2023-04-20 2023-04-20   1.000000   \n",
       "4       533       jukka.haavisto 2023-04-01 2023-06-30   0.750000   \n",
       "..      ...                  ...        ...        ...        ...   \n",
       "67      586      arto.kovalainen 2023-05-08 2023-05-10   1.000000   \n",
       "68      553          tuomas.kara 2023-04-19 2023-04-20   2.400000   \n",
       "69      549       tapio.tuomisto 2023-03-01 2023-04-30   0.500000   \n",
       "70      578       ilkka.vaisanen 2023-04-17 2023-06-02   1.000000   \n",
       "71      545  Antti-juho.nieminen 2023-04-04 2023-05-05   3.000000   \n",
       "\n",
       "    employee_day  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "..           ...  \n",
       "67           NaN  \n",
       "68           NaN  \n",
       "69           NaN  \n",
       "70           NaN  \n",
       "71           NaN  \n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['plan_id', 'employee', 'start', 'end', 'hours_day', 'employee_day'])\n",
    "\n",
    "for plan in data:\n",
    "    row = {'plan_id': plan['id'], 'employee': plan['assignee']['key'], 'start': plan['start'], 'end': plan['end'], 'hours_day': int(plan['secondsPerDay'])/(60*60)}\n",
    "    df.loc[len(df)] = row\n",
    "\n",
    "df['start'] = pd.to_datetime(df['start'], format='%Y/%m/%d')\n",
    "df['end'] = pd.to_datetime(df['end'], format='%Y/%m/%d')\n",
    "\n",
    "dfgroup = df\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n\\n# Create a new data frame with every day of the project\\ndate_range = pd.date_range(start=employee_data['start'].min(), end=employee_data['end'].max(), freq='D')\\nproject_dates = pd.DataFrame({'Project Dates': date_range})\\n\\n# Merge the new data frame with the employee data\\nmerged_data = pd.merge(project_dates, employee_data, how='left', left_on='Project Dates', right_on='start')\\n\\n# Fill in missing employees\\nmerged_data['employee'].fillna(method='ffill', inplace=True)\\n\\n# Create a new column with plan_id, employee and date for each day of the project for each employee\\nplanned_id = merged_data['plan_id'].apply(str)\\nmerged_data['Employee Project Dates'] = planned_id + ': ' + merged_data['employee'] + ': ' + merged_data['Project Dates'].dt.strftime('%Y-%m-%d')\\n\\n# Pivot the data to create a new column for each employee\\npivot_data = merged_data.pivot(index='Employee Project Dates', columns='employee', values='hours_day')\\n\\n# Reset the index and rename the columns\\npivot_data = pivot_data.reset_index().rename_axis(None, axis=1)\\n\\n# Display the updated data frame\\n# print(pivot_data)\\n\\n# Write the updated data frame to a new CSV file\\nmerged_data.to_csv('updated_employee_data.csv', index=False)\\n \""
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "employee_data = df.copy()\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "# Create a new data frame with every day of the project\n",
    "date_range = pd.date_range(start=employee_data['start'].min(), end=employee_data['end'].max(), freq='D')\n",
    "project_dates = pd.DataFrame({'Project Dates': date_range})\n",
    "\n",
    "# Merge the new data frame with the employee data\n",
    "merged_data = pd.merge(project_dates, employee_data, how='left', left_on='Project Dates', right_on='start')\n",
    "\n",
    "# Fill in missing employees\n",
    "merged_data['employee'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Create a new column with plan_id, employee and date for each day of the project for each employee\n",
    "planned_id = merged_data['plan_id'].apply(str)\n",
    "merged_data['Employee Project Dates'] = planned_id + ': ' + merged_data['employee'] + ': ' + merged_data['Project Dates'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Pivot the data to create a new column for each employee\n",
    "pivot_data = merged_data.pivot(index='Employee Project Dates', columns='employee', values='hours_day')\n",
    "\n",
    "# Reset the index and rename the columns\n",
    "pivot_data = pivot_data.reset_index().rename_axis(None, axis=1)\n",
    "\n",
    "# Display the updated data frame\n",
    "# print(pivot_data)\n",
    "\n",
    "# Write the updated data frame to a new CSV file\n",
    "merged_data.to_csv('updated_employee_data.csv', index=False)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JariKaijansinkko\\AppData\\Local\\Temp\\ipykernel_5088\\1902589200.py:32: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  all_dates = pd.date_range(start=begin, end=end, freq='D')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df['date_range'] = df.apply(lambda row: pd.date_range(start=row['start'], end=row['end'], freq='D'), axis=1)\n",
    "\n",
    "df_exploded = df.explode('date_range')\n",
    "\n",
    "df_summed = df_exploded.groupby(['date_range', 'employee'])['hours_day'].sum().reset_index()\n",
    "# df_summed\n",
    "plans = df_exploded.groupby(['date_range', 'employee'])['plan_id'].agg(lambda x: list(x)).reset_index()\n",
    "# Merge the new data frame with the employee data\n",
    "merged_data = pd.merge(df_summed, plans, how='left')\n",
    "# Read in the date table\n",
    "date_table = pd.read_csv('Datetable.csv', parse_dates=['Date'])\n",
    "# Convert the date column to a datetime object\n",
    "date_table['Date'] = pd.to_datetime(date_table['Date'])\n",
    "\n",
    "date_table.set_index('Date', inplace=True)\n",
    "\n",
    "\n",
    "df['date'] = df.apply(lambda row: pd.date_range(start=row['start'], end=row['end'], freq='D'), axis=1)\n",
    "\n",
    "df_exploded = df.explode('date')\n",
    "\n",
    "df_hours_sum = df_exploded.groupby(['date', 'employee'])['hours_day'].sum().reset_index()\n",
    "df_plan_agg = df_exploded.groupby(['date', 'employee'])['plan_id'].agg(lambda x: list(x)).reset_index()\n",
    "\n",
    "df_merged = pd.merge(df_hours_sum, df_plan_agg, on=['date', 'employee'])\n",
    "# Read in the date table and employee data table\n",
    "date_df = pd.read_csv('Datetable.csv')\n",
    "\n",
    "begin = '1/1/2023'\n",
    "end = '31/12/2023'\n",
    "\n",
    "all_dates = pd.date_range(start=begin, end=end, freq='D')\n",
    "all_names = df_merged['employee'].unique()\n",
    "name_date_df = pd.MultiIndex.from_product([all_names, all_dates], names=['employee', 'date']).to_frame(index=False)\n",
    "\n",
    "df_all_days = pd.merge(name_date_df, df_merged, on=['employee', 'date'], how='left').fillna({'hours_day': 0})\n",
    "\n",
    "df_all_days['date'] = df_all_days['date'].dt.floor('D')\n",
    "df_all_days[df_all_days['employee'] == 'tuomas.kara']\n",
    "\n",
    "\"\"\" # Create a new dataframe to hold the merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each employee in the employee data table\n",
    "for index, row in employee_data.iterrows():\n",
    "    # Create a new dataframe to hold the merged data for this employee\n",
    "    employee_merged_df = pd.DataFrame()\n",
    "    \n",
    "    # Get the date range for this employee\n",
    "    date_values = pd.date_range(start=row['start'], end=row['end'])\n",
    "    \n",
    "    # Create a new dataframe with the date range\n",
    "    dates_df = pd.DataFrame({'Date': date_values})\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Merge the date dataframe with the employee allocations for this employee\n",
    "    employee_allocations_df = pd.DataFrame(row['Date'], columns=['Allocation'])\n",
    "    # dates_with_allocations_df = pd.merge(dates_df, employee_allocations_df, how='left', left_on='Date', right_index=True)\n",
    "    \n",
    "    # Fill any missing allocations with 0\n",
    "    # dates_with_allocations_df.fillna(0, inplace=True)\n",
    "    \n",
    "    # Add the employee name to the dataframe\n",
    "    # dates_with_allocations_df['Employee'] = row['Employee Name']\n",
    "    \n",
    "    # Append the merged data for this employee to the overall merged dataframe\n",
    "    # merged_df = pd.concat([merged_df, dates_with_allocations_df])\n",
    "\n",
    "\n",
    "\n",
    "# Write the merged data to a new CSV file\n",
    "# merged_df.to_csv('merged_data.csv', index=False)\n",
    " \"\"\"\n",
    "# row.info()\n",
    "# dates_df.info()\n",
    "merged_data = df_all_days.copy()\n",
    "\n",
    "merged_data['allocation'] = 'Partly allocated'\n",
    "\n",
    "merged_data.loc[merged_data['hours_day'] >= 7.5, 'allocation'] = 'Fully allocated'\n",
    "merged_data.loc[merged_data['hours_day'] <= 0.1, 'allocation'] = 'Not allocated'\n",
    "\n",
    "\"\"\" merged_data['coefficient'] = 0.5\n",
    "\n",
    "merged_data.loc[merged_data['hours_day'] >= 7.5, 'coefficient'] = 1.0\n",
    "merged_data.loc[merged_data['hours_day'] <= 0.1, 'coefficient'] = 0.0 \"\"\"\n",
    "# merged_data.loc[merged_data['hours_day'] < 7.5 and merged_data['hours_day'] > 0.1 , 'allocation'] = 'Partly allocated'\n",
    "# merged_data['allocation'] = ''\n",
    "\n",
    "\n",
    "\n",
    "# rowvalue\n",
    "# plans\n",
    "# df_summed\n",
    "# merged_data\n",
    "\n",
    "# Write the updated data frame to a new CSV file\n",
    "merged_data.to_csv('updated_employee_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data.groupby('employee').sum()\n",
    "\n",
    "# pivot_data\n",
    "\n",
    "# date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(f'{base_url}/rest/tempo-teams/2/team', headers=header)\n",
    "teams = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jani.lundan\n",
      "jarkko.sillanpaa\n",
      "juha.patrikainen\n",
      "juho.lehtonen\n",
      "jukka.haavisto\n",
      "jyri.tienhaara\n",
      "kai.jokiniemi\n",
      "matias.ijas\n",
      "mika.tavi\n",
      "tapio.tuomisto\n",
      "teemu.partanen\n",
      "tuomas.kara\n",
      "vilma.pohjonen\n"
     ]
    }
   ],
   "source": [
    "team_members = requests.get(f'{base_url}/rest/tempo-teams/2/team/42/member', headers=header).json()\n",
    "for member in team_members:\n",
    "    print(member['member']['name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
